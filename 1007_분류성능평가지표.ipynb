{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #분류(Classification) 성능 평가 지표\n",
    "### 분류 성능 평가 지표\n",
    "1. 정확도(Accuracy)\n",
    "2. 오차행렬(Confusion Matrix)\n",
    "3. 정밀도(Precision),재현율(Recall)\n",
    "4. F1 스코어\n",
    "6. ROC AUC\n",
    "\n",
    "#### 1. <b>정확도(Accuaracy)</b>\n",
    "- 정확도는 직관적으로 모델 예측 성능을 나타내는 평가 지표\n",
    "- 이진 분류의 경우 데이터의 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지 않음\n",
    "- 특히 정확도는 불균형한(imbalanced) 레이블 값 분포에서 ML 모델의 성능을 판단할 경우, 적합한 평가 지표가 아님\n",
    "- <b>정확도(Accuracy) = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수</b>\n",
    "\n",
    "#### 2. <b>오차행렬(Confusion Maitix</b>\n",
    "- 오차 행렬은 <b>이진 분류</b>의 예측 오류가 얼마인지에 더불어 어떠한 유형의\n",
    "예측 오류가 발생하고 있는지를 함께 나타내는 지표\n",
    "- Positive(양성), Negative(음성) vs. TRUE(맞게 분류), FALSE(틀리게 분류)\n",
    "- 4분면의 왼쪽과 오른쪽은 예측된 class를 기준으로 Negative와 Positive\n",
    "로 분류\n",
    "- 위와 아래는 실제 class를 기준으로 Negative와 Positive로 분류\n",
    "\n",
    "![\"confusion_matrix](https://user-images.githubusercontent.com/58713684/93588442-61649f00-f9e6-11ea-8303-c00bfb38db08.png)\n",
    "- 정확도 = 예측 결과와 실제 값이 동일한 건수/ 전체 데이터 수 = (TN+TP)/(TN+FP+FN+TP)\n",
    "1. TN은 예측값을 Negative 값인 0으로 예측했고 실제값 또한 Negative 값인 0일 때\n",
    "2. FP은 예측값을 Positive 값인 1으로 예측했는데 실제값은 Negative 값인 0일 때\n",
    "3. FN은 예측값을 Negative 값인 0으로 예측했는데 실제값은 Positive 값인 1일 때\n",
    "4. TP은 예측값을 Positive 값인 1으로 예측했고 실제값 또한 Positive 값인 1일 때\n",
    "\n",
    "#### 3. <b>정밀도(Precision) & 재현율(Recall)</b>\n",
    "- <b>정밀도</b>는 예측을 Positive로 한 대상 중에 예측을 실제 값이 Positvie로 일치한 데이터의 비율을 뜻함\n",
    "- <b>재현율</b>은 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율을 뜻함\n",
    "- 정밀도 = TP / (FP + TP)\n",
    "    - precision_score()\n",
    "- 재현율 = TP / (FN + TP)\n",
    "    - recall_score()\n",
    "- <b>재현율</b>이 상대적으로 더 중요한 지표인 경우는 실제 Positvie 양성인 데이터 예측을 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우 : 암진단, 금융사기 판별\n",
    "- <b>정밀도</b>가 상대적으로 더 중요한 지표인 경우는 실제 Negative 음성인 데이터 예측을 Positive 양성으로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우 : 스팸 메일\n",
    "- 불균형한 레이블 클래스를 가지는 이진 분류 모델에서는 많은 데이터 중에서 중점적으로 찾아야 하는 매우 적은 수의 결과값에 Positive를 설정해 1값을 부여하고, 그렇지 않은 경우는 Negative로 0 값을 일반적으로 부여\n",
    "\n",
    "#### <b>정밀도/재현율 트레이드오프(Trade off)</b>\n",
    "- 분류하려는 업무의 특성상 정밀도 또는 재현율이 특별히 강조되어야 할 경우 분류의 결정 임계값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있음\n",
    "- 정밀도와 재현율은 상호 보완적인 평가 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉬움\n",
    "- 정밀도/재현율의 트레이드오프(Trade-off)\n",
    "\n",
    "#### 4. <b>F1 Score</b>\n",
    "- F1 스코어(Score)는 정밀도와 재현율을 결합한 지표\n",
    "- F1 스코어는 정밀도와 재현율이 어느 한쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가짐\n",
    "- F1 스코어의 공식\n",
    "    - 𝑭𝟏 = 𝟐 ∗ (𝒑𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏 ∗ 𝒓𝒆𝒄𝒂𝒍𝒍)/(𝒑𝒓𝒆𝒄𝒊𝒔𝒊𝒐𝒏 + 𝒓𝒆𝒄𝒂𝒍𝒍)\n",
    "- A 예측 모델의 경우 정밀도 0.9 재현율이 0.1로 근단적인 차이가 나고,\n",
    "- B 예측 모델은 정밀도가 0.5, 재현율이 0.5로 정밀도와 재현율이 큰 차이가 없다면\n",
    "- A 예측 모델의 F1스코어는 0.18이고, B예측 모델의 F1 스코어는 0.5로 B모델이 A모델에 비해 매우 우수한 F1 스코어를 가짐\n",
    "- 사이킷런은 F1 Score를 위해 F1_score() 함수를 제공\n",
    "\n",
    "#### **5.ROC 곡선과 AUC**\n",
    "- ROC 곡선(Receiver Operation Characteristic Curve)과 이에 기반한 AUC 스코어는 이진 분류의 예측 성능 측정에서 중요하게 사용되는 지표\n",
    "- 일반적으로 의학 분야에서 많이 사용되지만, 머신러닝의 이진 분류 모델의 예측 성능을 판단하는 중요한 평가 지표\n",
    "- ROC 곡선은 FPR(False Positive Rate)이 변할 때 TPR(True PositiveRate)이 어떻게 변하는지를 나타내는 곡선\n",
    "- FPR을 X축으로, TPR을 Y축으로 잡으면 FPR이 변화에 따른 TPR의 변화가 곡선 형태로 나타냄\n",
    "- 분류의 성능 지표로 사용되는 것은 ROC 곡선 면접에 기반한 AUC값으로 결정\n",
    "- AUC(Area Under Curve) 값이 ROC 곡선 밑의 면적을 구한 것이로써 일반적으로 **1에 가까울수록 좋은 수치**\n",
    "- TPR은 Ture Positive Rate의 약자이며, 이는 재현율을 나타냄\n",
    "- TPR은 TP / (FN + TP), 즉 재현율은 민감도로도 불림\n",
    "- FPR은 실제 Negative(음성)을 잘못 예측한 비율을 나타냄\n",
    "- 즉 실제는 Negative인데 Positive 또는 Negative로 예측한 것 중 Positive로 잘못 예측 비율\n",
    "- FPR은 FP / (FP + TN)\n",
    "- 사이킷런은 임계값에 따른 ROC 곡선 데이터를 roc_curve()로\n",
    "- AUC 스코어를 roc_auc_score() 함수로 제공\n",
    "\n",
    "#### **정리**\n",
    "- **이진분류**에서 정밀도, 재현율, F1 스코어, AUC 스코어가 주로 성능평가 지표로 활용\n",
    "- **오차 행렬**은 실제 클래스 값과 예측 클래스 값의 True, False에 따라 TN, FP, FN ,TP로 매핑되는 4분면 행렬을 제공\n",
    "- **정밀도와 재현율**은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 지표이며, 분류 결정 임계값을 조정해 정밀도 또는 재현율은 수치를 높이거나 낮출 수 있음\n",
    "- **F1스코어**는 정밀도와 재현율이 어느 한쪽으로 치우치지 않을 때 좋은 값을 가짐\n",
    "- **AUC스코어**는 ROC 곡선 밑의 면적을 구한 것으로 1에 가까울 수록 좋은 수치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### === === === === === === === === === === === === === === ===\n",
    "# #실습\n",
    "#### **정확도(Accuracy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# sklearn import 하기\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit( ) 메소드는 아무것도 학습하지 않음.\n",
    "    def fit(self, X , y=None):\n",
    "        pass\n",
    "\n",
    "    # predict( ) 메소드는 단순히 Sex feature가 1 이면 0 , 그렇지 않으면 1 로 예측함.\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( ( X.shape[0], 1 ))\n",
    "        for i in range (X.shape[0]) :\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "# 레이블 인코딩 수행.\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할.\n",
    "titanic_df = pd.read_csv('D:/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    " test_size=0.2, random_state=0)\n",
    "# 위에서 생성한 Dummy Classifier를 이용하여 학습/예측/평가 수행.\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train ,y_train)\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test , mypredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "### digits.data.shape: (1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n",
      "### digits.target.shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "\n",
    "    # 입력값으로 들어오는 X 데이터 셋의 크기만큼 모두 0값으로 만들어서 반환\n",
    "    def predict(self,X):\n",
    "        return np.zeros( (len(X), 1) , dtype=bool)\n",
    "# 사이킷런의 내장 데이터 셋인 load_digits( )를 이용하여 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "print(digits.data)\n",
    "print(\"### digits.data.shape:\", digits.data.shape)\n",
    "print(digits.target)\n",
    "print(\"### digits.target.shape:\", digits.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digits번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 False이고 0으로 변환.\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split( digits.data, y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기 : (450,)\n",
      "테스트 세트 레이블 0 과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는:0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인.\n",
    "print('레이블 테스트 세트 크기 :', y_test.shape)\n",
    "print('테스트 세트 레이블 0 과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train , y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는:{:.3f}'.format(accuracy_score(y_test , fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **정밀도와 재현율**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정밀도: 0.0\n",
      "재현율: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score\n",
    "print(\"정밀도:\", precision_score(y_test, fakepred))\n",
    "print(\"재현율:\", recall_score(y_test, fakepred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **오차행렬, 정확도, 정밀도, 재현율을 한꺼번에 계산하는 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score , recall_score , confusion_matrix\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy , precision ,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습데이터/테스트 데이터 분할.\n",
    "titanic_df = pd.read_csv('D:/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    " test_size=0.20, random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Precision/Recall Trade-off**\n",
    "- predict_proba( ) 메소드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba()결과 Shape : (179, 2)\n",
      "pred_proba array에서 앞 3개만 샘플로 추출 \n",
      ": [[0.46254265 0.53745735]\n",
      " [0.87868482 0.12131518]\n",
      " [0.87716717 0.12283283]]\n",
      "두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46254265 0.53745735 1.        ]\n",
      " [0.87868482 0.12131518 0.        ]\n",
      " [0.87716717 0.12283283 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba , pred.reshape(-1,1)],axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n',pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 스코어: 0.7805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test , pred)\n",
    "print('F1 스코어: {0:.4f}'.format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **ROC& AUC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 추출을 위한 임곗값 배열의 index: [ 1  6 11 16 21 26 31 36 41 46 51]\n",
      "샘플 index로 추출한 임곗값:  [0.97 0.65 0.63 0.56 0.45 0.4  0.35 0.15 0.13 0.11 0.11]\n",
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.076 0.127 0.169 0.203 0.466 0.585 0.686 0.797]\n",
      "샘플 임곗값별 TPR:  [0.033 0.639 0.721 0.754 0.803 0.836 0.885 0.902 0.934 0.967 0.984]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# 레이블 값이 1일때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출.\n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n",
    "print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max predict_proba: 0.9650310806706003\n",
      "thresholds[0]: 1.9650310806706002\n",
      "샘플 추출을 위한 임곗값 배열의 index 10개: [ 0  5 10 15 20 25 30 35 40 45 50]\n",
      "샘플용 10개의 임곗값:  [1.97 0.75 0.63 0.59 0.49 0.4  0.35 0.23 0.13 0.12 0.11]\n",
      "샘플 임곗값별 FPR:  [0.    0.017 0.034 0.051 0.127 0.161 0.203 0.331 0.585 0.636 0.797]\n",
      "샘플 임곗값별 TPR:  [0.    0.475 0.689 0.754 0.787 0.836 0.869 0.902 0.918 0.967 0.967]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# 레이블 값이 1일때의 예측 확률을 추출\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "print('max predict_proba:', np.max(pred_proba_class1))\n",
    "fprs , tprs , thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "print('thresholds[0]:', thresholds[0])\n",
    "# 반환된 임곗값 배열 로우가 47건이므로 샘플로 10건만 추출하되, 임곗값을 5 Step으로 추출.\n",
    "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def roc_curve_plot(y_test , pred_proba_c1):\n",
    "    # 임곗값에 따른 FPR, TPR 값을 반환 받음.\n",
    "    fprs , tprs , thresholds = roc_curve(y_test ,pred_proba_c1)\n",
    "    # ROC Curve를 plot 곡선으로 그림.\n",
    "    plt.plot(fprs , tprs, label='ROC')\n",
    "    # 가운데 대각선 직선을 그림.\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "\n",
    "    # FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    plt.xlabel('FPR( 1 - Sensitivity )'); plt.ylabel('TPR( Recall )')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "roc_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC 값: 0.9025\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "### roc_auc_score(y_test, y_score)로 y_score는 predict_proba()로 호출된 예측 확률 ndarray중 Positive\n",
    "#pred = lr_clf.predict(X_test)\n",
    "#roc_score = roc_auc_score(y_test, pred)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "roc_score = roc_auc_score(y_test, pred_proba)\n",
    "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
